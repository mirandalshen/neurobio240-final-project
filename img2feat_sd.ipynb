{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfda942-aca2-4f74-8bf8-2b1c782a8e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import os\n",
    "\n",
    "local_path = '/shared/home/mis6559/neurobio240/nsd/nsddata_stimuli/stimuli/nsd/nsd_stimuli.hdf5'\n",
    "os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    fs.get(\n",
    "        'natural-scenes-dataset/nsddata_stimuli/stimuli/nsd/nsd_stimuli.hdf5',\n",
    "        local_path\n",
    "    )\n",
    "    print(\"nsd_stimuli.hdf5 downloaded successfully!\")\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af367c5-723e-4f79-9da6-44f2b51bfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib==3.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d1da1-fd4c-4524-8293-57a055511cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from nsd_access import NSDAccess\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch import autocast\n",
    "from contextlib import nullcontext\n",
    "from einops import repeat\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "\n",
    "def load_model_from_config(config, ckpt, gpu, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\", m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\", u)\n",
    "    model.cuda(f\"cuda:{gpu}\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_img_from_arr(img_arr, resolution):\n",
    "    image = Image.fromarray(img_arr).convert(\"RGB\")\n",
    "    image = image.resize((resolution, resolution), resample=Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2.*image - 1.\n",
    "\n",
    "# Place at the top (global scope)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--imgidx\", nargs=2, type=int, default=[0, 73000], help=\"Image index range: start end\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"GPU device id\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "def main():\n",
    "    seed_everything(args.seed)\n",
    "    start_idx, end_idx = args.imgidx\n",
    "    gpu = args.gpu\n",
    "\n",
    "    resolution = 320\n",
    "    batch_size = 1\n",
    "    ddim_steps = 50\n",
    "    ddim_eta = 0.0\n",
    "    strength = 0.8\n",
    "    scale = 5.0\n",
    "    t_enc = int(strength * ddim_steps)\n",
    "\n",
    "    nsd_path = '/shared/home/mis6559/neurobio240/nsd/'  # local path now!\n",
    "\n",
    "    nsda = NSDAccess(nsd_path)\n",
    "\n",
    "    config_path = '../neurobio240/stable-diffusion/configs/stable-diffusion/v1-inference.yaml'\n",
    "    ckpt_path = '../neurobio240/stable-diffusion/models/ldm/stable-diffusion-v1/sd-v1-4.ckpt'\n",
    "    config = OmegaConf.load(config_path)\n",
    "\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model = load_model_from_config(config, ckpt_path, gpu)\n",
    "    device = torch.device(f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    sampler = DDIMSampler(model)\n",
    "    sampler.make_schedule(ddim_num_steps=ddim_steps, ddim_eta=ddim_eta, verbose=False)\n",
    "\n",
    "    save_dir_latent = f'./nsdfeat/init_latent/'\n",
    "    save_dir_cond = f'./nsdfeat/c/'\n",
    "    os.makedirs(save_dir_latent, exist_ok=True)\n",
    "    os.makedirs(save_dir_cond, exist_ok=True)\n",
    "\n",
    "    precision_scope = autocast if torch.cuda.is_available() else nullcontext\n",
    "\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        latent_path = os.path.join(save_dir_latent, f\"{idx:06}.npy\")\n",
    "        cond_path = os.path.join(save_dir_cond, f\"{idx:06}.npy\")\n",
    "    \n",
    "        if os.path.exists(latent_path) and os.path.exists(cond_path):\n",
    "            continue  # Already processed\n",
    "    \n",
    "        try:\n",
    "            print(f\"Processing image {idx:06}\")\n",
    "\n",
    "            prompts = nsda.read_image_coco_info([idx], info_type='captions')\n",
    "            prompt = [p['caption'] for p in prompts]\n",
    "            image_array = nsda.read_images(idx)\n",
    "            init_image = load_img_from_arr(image_array, resolution).to(device)\n",
    "            init_image = repeat(init_image, '1 ... -> b ...', b=batch_size)\n",
    "\n",
    "            init_latent = model.get_first_stage_encoding(model.encode_first_stage(init_image))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with precision_scope(\"cuda\"):\n",
    "                    with model.ema_scope():\n",
    "                        uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "                        c = model.get_learned_conditioning(prompt).mean(dim=0).unsqueeze(0)\n",
    "                        z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(device))\n",
    "                        samples = sampler.decode(z_enc, c, t_enc, unconditional_guidance_scale=scale, unconditional_conditioning=uc)\n",
    "\n",
    "            np.save(f'{save_dir_latent}/{idx:06}.npy', init_latent.cpu().numpy().flatten())\n",
    "            np.save(f'{save_dir_cond}/{idx:06}.npy', c.cpu().numpy().flatten())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {idx}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6dcead-b8ad-4780-a06c-99b03376c500",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
